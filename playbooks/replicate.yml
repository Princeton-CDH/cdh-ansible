- name: Replace database and media content between deploy environments
  hosts: geniza_qa
  connection: ssh
  remote_user: pulsys
  # override default location for db backup
  vars:
    - timestamp: "{{ ansible_date_time.date }}"
    - backup_dir : "/home/{{ deploy_user }}/migrate/"
    - db_backup_filename: "{{ timestamp }}_{{ application_db_name }}.sql.bz2"
    - db_backup_path: "{{ backup_dir }}{{ db_backup_filename }}"
    - media_backup_filename: "{{ timestamp }}_{{ app_name }}_media.tar.gz"
    - media_backup_path: "{{ backup_dir }}{{ media_backup_filename}}"
    # testing replicating to localhost/dev for now
    - dest_host: localhost
    - dest_backup_dir : "/tmp/migrate/"
    - dest_backup_path: "{{ dest_backup_dir }}{{ db_backup_filename }}"
    - dest_backup_path_unzipped:  "{{ dest_backup_path | replace('.bz2', '') }}"
    - dest_postgres_host: localhost
    - dest_media_backup_path: "{{ dest_backup_dir }}{{ media_backup_filename}}"
    # TODO: setup group vars for dev/local
    - dest_media_dir: /Users/rkoeser/workarea/github/geniza/media
  tasks:
    - name: Generate a database dump
      # use existing postgres backup task with customized backup path
      # (role ensures backup dir exists)
      include_role:
        name: postgresql
        tasks_from: backup_db.yml

    - name: Create an archive of application media files
      community.general.archive:
        path: "{{ media_root }}"
        dest: "{{ media_backup_path }}"
        owner: "{{ deploy_user }}"
      become: true
      become_user: "{{ deploy_user }}"

    - name: Create backup path on destination {{ dest_host }}
      file:
        dest: "{{ dest_backup_path | dirname }}"
        mode: 0777
        # owner: "{{ deploy_user }}"
        state: directory
      delegate_to: "{{ dest_host }}"

    - name: Sync database dump to destination host
      # run rsync on dest machine to pull db dump from the source machine
      ansible.builtin.command: /usr/bin/rsync -avz "{{ ansible_user }}@{{ ansible_hostname }}:{{ db_backup_path }}" "{{ dest_backup_path }}" -e "ssh -o StrictHostKeyChecking=no"
      # become: true
      # become_user: "{{ deploy_user }}"
      delegate_to: "{{ dest_host }}"

    - name: Sync media to destination host
      # run rsync on dest machine to pull db dump from the source machine
      ansible.builtin.command: /usr/bin/rsync -avz "{{ ansible_user }}@{{ ansible_hostname }}:{{ media_backup_path }}" "{{ dest_backup_dir }}" -e "ssh -o StrictHostKeyChecking=no"
      # become: true
      # become_user: "{{ deploy_user }}"
      delegate_to: "{{ dest_host }}"

    - name: Make sure unzipped database dump does not exist (if it does, bunzip2 will fail)
      ansible.builtin.file:
        path: "{{ dest_backup_path_unzipped }}"
        state: absent
      delegate_to: "{{ dest_host }}"

    # postgres module can create zipped dump file, but at least on OSX
    # it fails to unzip when attempting to restore;
    # use command line since builtin unarchive task does not handle bz2
    - name: Unzip dumped database on {{ dest_host }}
      ansible.builtin.command: bunzip2 "{{ dest_backup_path }}"
      delegate_to: "{{ dest_host }}"

    # if we don't clear the database first, loading the dump results in
    # errors/warnings about constraints that already exist
    # NOTE: in local setup, remove database fails if django is running (client connected to db)
    - name: Remove the database "{{ application_db_name }}" on target host {{ dest_host }} if it exists
      community.postgresql.postgresql_db:
        name: "{{ application_db_name }}"
        login_host: '{{ dest_postgres_host }}'
        login_user: '{{ application_dbuser_name }}'
        login_password: '{{ application_dbuser_password }}'
        state: "absent"
      delegate_to: "{{ dest_host }}"

    - name: Create empty database "{{ application_db_name }}" on target host {{ dest_host }}
      community.postgresql.postgresql_db:
        name: "{{ application_db_name }}"
        login_host: '{{ dest_postgres_host }}'
        login_user: '{{ application_dbuser_name }}'
        login_password: '{{ application_dbuser_password }}'
        state: "present"
        owner: '{{ application_dbuser_name }}'
      delegate_to: "{{ dest_host }}"

    - name: Load the database "{{ application_db_name }}" on target host {{ dest_host }}
      community.postgresql.postgresql_db:
        name: "{{ application_db_name }}"
        encoding: 'UTF-8'
        login_host: '{{ dest_postgres_host }}'
        login_user: '{{ application_dbuser_name }}'
        login_password: '{{ application_dbuser_password }}'
        owner: '{{ application_dbuser_name }}'
        target: "{{ dest_backup_path_unzipped }}"
        state: "restore"
      # become: true
      # become_user: postgres
      delegate_to: "{{ dest_host }}"
      # async: 1800
      # poll: 60

    - name: Extract media to destination media directory
      ansible.builtin.unarchive:
        src: "{{ dest_media_backup_path }}"
        dest: "{{ dest_media_dir }}"
      delegate_to: "{{ dest_host }}"


# could django migration be done as a second playbook? use existing role/task
- hosts: localhost    # local won't actually work without some setup...
  connection: ssh
  remote_user: pulsys
  # override default location for db backup
  # vars:
  tasks:
  - name: Run django migrations on destination
    include_role:
      name: django
      tasks_from: migrate
